## Model Fine-Tuning

We fine-tuned the **Gemini 2.0 Flash** base model using a custom dataset of medical Q&A pairs that we generated with a controlled system prompt. Each example alternated between **Clinician** and **Researcher** personas, ensuring that the model was exposed to both concise clinical answers and longer research-focused explanations. After cleaning, deduplicating, and formatting the data into Vertex AI’s supervised tuning structure, we uploaded the training and validation sets to GCS and started an adapter-based tuning job.

The tuning run completed successfully. Across roughly **114 steps**, the model showed steady learning behavior: **validation accuracy reached 0.87**, and training accuracy remained close behind at **0.83–0.85**, indicating reasonable generalization for this type of dataset. The **loss curve declined consistently**, ending near **0.4**, which matches healthy optimization for an adapter-based setup. Prediction counts stayed stable throughout training, confirming that the dataset was processed correctly. Two checkpoints were produced, and the final default checkpoint was deployed automatically as the tuned model **matling-medical-demo-v3**.

Early functional tests show that the tuned model responds in a stable way to the `"Persona: …\n\nQuestion: …"` format and appears more consistent in following the persona instructions, although a more complete evaluation will be needed to measure the extent of these improvements. Because Vertex AI’s fine-tuning pipeline uses lightweight adapters, the tuned model adds only a small set of parameters on top of the frozen base model. This typically keeps latency and cost close to the base model and makes it easy to iterate or roll back if needed. For deployment, this tuned endpoint now serves as our **primary model**, and our CLI and downstream services can query it directly without any changes to the interface.
